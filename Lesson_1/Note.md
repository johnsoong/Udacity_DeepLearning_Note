# 从机器学习到深度学习

## 监督学习

分类：给定输入和标记的任务，典型情况是有很多有标记的样本，对新来的样本进行分类
分类/预测是机器学习的基石，可以推广到检测和排序

Q1：假设你的车上有摄像头拍摄前面的街道，如何利用分类器检测行人

找到可疑区域，进行是否为行人的分类器训练

Q2：对于搜索请求，如何使用分类器实现与请求相关的页面

将搜索请求和网站作为输入，进行是否相关的分类器训练

## Logistic Classifier

$\frac{1}{e^{WX+b}+1}$

$$W$$ 为权重，$b$ 为偏置

利用softmax函数使得结果输出为类别概率形式

当score成倍（倍数>1）增加，那么输出的概率将趋近于0或1
即假使你的输出很大，则分类器的结果相对自信

## One-Hot Encoding
一位有效编码：使得向量每个类都有一个特殊位置

当有成千上万个类别的时候，One-Hot相当浪费空间，一般使用嵌（Embedding）入解决这个问题/bold{}

## 交叉熵（Cross-Entropy）

定义为$D(S,L)=-/sum{Llog(S)}$，用以度量真实标签和输出概率的差距

其中L为label（One-Hot后的标记）,S为输出的概率

为了使得差距最小，我们需要最小化交叉熵

常用方法是梯度下降，对罚函数每一个变量求偏导，使变量加上偏导，迭代直到达到全局最小

考虑到数值计算的不稳定性，我们要使得损失函数不要过大或者过小

1）变量满足均值为0，方差相同
2）较好的初始化权重，使用均值为0方差较小的高斯分布中取得（sigma觉得了初始点你输出的数量级，也决定了初始化概率分布的峰值）
